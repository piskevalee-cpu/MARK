#!/usr/bin/env python3
"""
MARK - AI Terminal Wrapper

Main entry point for the MARK application.
A universal AI API wrapper with persistent memory and Rich UI.
"""

import asyncio
import sys
import re
from datetime import datetime
from typing import List, Optional

from rich.console import Console

# Local imports
from .config import (
    AVAILABLE_MODELS,
    Config,
    get_api_key,
    get_system_prompt,
    load_config,
    save_api_key,
    save_config,
    MARK_DIR,
)
from .database import MemoryDB, init_database
from .memory import MemoryManager
from .providers import GeminiProvider, GroqProvider
from .providers.base import AIProvider, Message
from .ui import MarkInterface
from .ui.components import apply_theme, THEMES
from .ui.interface import SetupWizard


# =============================================================================
# Application Class
# =============================================================================

class MarkApp:
    """Main MARK application class."""
    
    def __init__(self):
        self.console = Console()
        self.ui = MarkInterface(self.console)
        self.config: Optional[Config] = None
        self.provider: Optional[AIProvider] = None
        self.memory: Optional[MemoryManager] = None
        self.db: Optional[MemoryDB] = None
        self.context: List[Message] = []
        self._running = False
    
    async def initialize(self) -> bool:
        """
        Initialize the application.
        
        Returns:
            True if initialization successful
        """
        # Ensure data directory exists
        MARK_DIR.mkdir(parents=True, exist_ok=True)
        
        # Initialize database
        init_database()
        self.db = MemoryDB()
        self.memory = MemoryManager(self.db)
        
        # Load or create config
        self.config = load_config()
        
        # Apply theme from config
        apply_theme(self.config.theme)
        
        # Check if provider needs API key
        provider = self.config.default_provider.upper()
        
        # LOCAL and NONE providers don't need API keys
        if provider in ["LOCAL", "NONE"]:
            if provider == "NONE":
                # No provider configured yet, but don't force setup
                self.provider = None
                return True
            else:
                # LOCAL provider (Ollama)
                try:
                    self.provider = self._create_provider(
                        self.config.default_provider,
                        "",
                        self.config.default_model
                    )
                    return True
                except Exception as e:
                    self.ui.print_error(f"Initialization error: {e}")
                    return False
        
        # Cloud providers need API key
        api_key = get_api_key(self.config.default_provider)
        
        if not api_key:
            # Run setup wizard
            return await self._run_setup()
        
        # Initialize provider based on config
        try:
            self.provider = self._create_provider(
                self.config.default_provider,
                api_key,
                self.config.default_model
            )
            
            # Validate API key
            if not await self.provider.validate_api_key():
                self.ui.print_error(
                    "API key invalid or expired.",
                    suggestion="Run /config to update configuration."
                )
                return await self._run_setup()
            
            return True
            
        except Exception as e:
            self.ui.print_error(f"Initialization error: {e}")
            return False
    
    def _create_provider(self, provider_name: str, api_key: str, model: str) -> AIProvider:
        """Create the appropriate provider instance based on provider name."""
        if provider_name.lower() == "groq":
            return GroqProvider(api_key=api_key, model=model)
        elif provider_name.lower() == "local":
            from .providers import OllamaProvider
            return OllamaProvider(api_key="", model=model)
        else:
            # Default to GOOGLE
            return GeminiProvider(api_key=api_key, model=model)
    
    async def _run_setup(self) -> bool:
        """Run the setup wizard."""
        wizard = SetupWizard(self.console)
        setup_config = wizard.run()
        
        if not setup_config:
            return False
        
        # Save API key
        api_key = setup_config.get("api_key")
        provider = setup_config.get("provider", "GOOGLE")
        model = setup_config.get("model", "gemini-2.5-flash")
        
        if api_key:
            save_api_key(provider, api_key)
        
        # Update config
        self.config.default_provider = provider
        self.config.default_model = model
        
        # Save language if provided by wizard
        if "language" in setup_config:
            self.config.language = setup_config["language"]
            
        save_config(self.config)
        
        # Handle NONE provider (no AI configured)
        if provider == "NONE":
            self.provider = None
            self.ui.print_system_message(
                "Setup complete! Use /model to configure an AI model later.",
                style="success"
            )
            return True
            
        # Initialize provider using helper
        self.provider = self._create_provider(provider, api_key, model)
        
        # Validate
        self.console.print()
        with self.console.status("[bold purple]Validating API key..."):
            if await self.provider.validate_api_key():
                self.ui.print_system_message(
                    "Setup complete! MARK is ready.",
                    style="success"
                )
                return True
            else:
                self.ui.print_error(
                    "Invalid API key.",
                    suggestion="Check key and try again."
                )
                return False

    
    async def run(self):
        """Main application loop."""
        self._running = True
        
        # Show welcome
        self.ui.print_welcome()
        
        # Print header
        self.ui.print_header(
            model=self.config.default_model,
            provider=self.config.default_provider,
            connected=True
        )
        
        # Print footer hint
        self.ui.print_footer()
        self.console.print()
        
        while self._running:
            try:
                # Get user input (Standard)
                user_input = self.ui.prompt_input()
                
                if not user_input.strip():
                    continue
                
                # Process input
                await self._process_input(user_input)
                
            except KeyboardInterrupt:
                self.console.print()
                self.ui.print_system_message(
                    "Press Ctrl+C again to exit, or type /quit",
                    style="warning"
                )
                try:
                    user_input = self.ui.prompt_input()
                    if user_input.strip():
                        await self._process_input(user_input)
                except KeyboardInterrupt:
                    self._running = False
            except EOFError:
                self._running = False
        
        # Goodbye
        self.console.print()
        self.ui.print_system_message("Goodbye! üëã", style="info")
    
    async def _process_input(self, user_input: str):
        """Process user input."""
        user_input = user_input.strip()
        
        # Check for commands
        if user_input.startswith("/"):
            await self._handle_command(user_input)
            return
        
        # Check for memory command
        if self.memory.is_memory_command(user_input):
            success, message = self.memory.process_memory_command(user_input)
            self.ui.print_system_message(message, style="success" if success else "warning")
            return
        
        # Regular message - send to AI
        await self._send_to_ai(user_input)
    
    async def _handle_command(self, command: str):
        """Handle slash commands."""
        parts = command.lower().split()
        cmd = parts[0]
        args = parts[1:] if len(parts) > 1 else []
        
        if cmd in ["/quit", "/exit", "/q"]:
            self._running = False
            
        elif cmd in ["/help", "/h", "/?"]:
            self.ui.print_help()
            
        elif cmd in ["/clear", "/cls"]:
            self.ui.clear()
            self.ui.print_header(
                model=self.config.default_model,
                provider=self.config.default_provider
            )
            
        elif cmd == "/model":
            # Pass the input queue to handle interactive prompts if needed
            # Since self.ui.prompt_input is blocking, we can just use that inside the handler
            await self._handle_model_command(args)
            
        elif cmd == "/stats":
            self._show_stats()
            
        elif cmd == "/memory":
            await self._handle_memory_command(args)
            
        elif cmd == "/reset":
            self.context = []
            if self.provider:
                self.provider.reset_session_usage()
                if hasattr(self.provider, 'reset_chat'):
                    self.provider.reset_chat()
            self.ui.print_system_message("Session reset.", style="success")
            
        elif cmd == "/config":
            await self._run_setup()
        
        elif cmd == "/kleos":
            prompt = " ".join(args).strip()
            if not prompt:
                self.ui.print_system_message("Usage: /kleos <prompt>", "warning")
            else:
                await self._handle_kleos_mode(prompt)
            
        elif cmd in ["/changeusr", "/changename"]:
            new_name = " ".join(args).strip()
            if not new_name:
                self.ui.print_system_message("Usage: /changeusr <new_name>", "warning")
            else:
                self.config.user_name = new_name
                save_config(self.config)
                self.ui.print_system_message(f"User name updated to: {new_name}", "success")
            
        elif cmd in ["/toggle-stats", "/ts"]:
            self.config.show_stats = not self.config.show_stats
            save_config(self.config)
            status = "enabled" if self.config.show_stats else "disabled"
            self.ui.print_system_message(f"Response statistics {status}.", "success")
            
        elif cmd == "/theme":
            theme_name = args[0] if args else ""
            if not theme_name:
                self.ui.print_system_message(
                    f"Available themes: {', '.join(THEMES.keys())}\nUsage: /theme <name>",
                    "info"
                )
            else:
                if apply_theme(theme_name):
                    self.config.theme = theme_name
                    save_config(self.config)
                    self.ui.print_system_message(f"Theme updated to: {theme_name}", "success")
                    # Refresh header to show new colors
                    self.ui.print_header(
                        model=self.config.default_model,
                        provider=self.config.default_provider
                    )
                else:
                    self.ui.print_error(
                        f"Theme '{theme_name}' not found.",
                        suggestion=f"Available: {', '.join(THEMES.keys())}"
                    )

        else:
            self.ui.print_system_message(
                f"Unknown command: {cmd}\nUse /help to see commands.",
                style="warning"
            )
    
    async def _handle_model_command(self, args: List[str]):
        """Handle /model command - unified provider/model selection."""
        import httpx
        
        # Check if Ollama is running and get available models
        ollama_models = []
        ollama_available = False
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get("http://localhost:11434/api/tags")
                if response.status_code == 200:
                    ollama_available = True
                    data = response.json()
                    ollama_models = [m["name"] for m in data.get("models", [])]
        except Exception:
            pass
        
        # Build providers list dynamically
        providers = ["groq", "GOOGLE"]
        if ollama_available:
            providers.append("LOCAL")
        
        # STEP 1: Provider Selection
        self.console.print()
        self.console.print("[bold cyan]‚îÅ‚îÅ‚îÅ SELECT PROVIDER ‚îÅ‚îÅ‚îÅ[/]")
        for i, p in enumerate(providers, 1):
            indicator = "‚Üí" if p.upper() == self.config.default_provider.upper() else " "
            label = p.upper()
            if p == "LOCAL":
                label = f"LOCAL - Ollama ({len(ollama_models)} models)"
            self.console.print(f"  {indicator} [{i}] {label}")
        
        if not ollama_available:
            self.console.print("[dim]  (LOCAL not available - Ollama not running)[/]")
        
        self.console.print(f"\nChoice (1-{len(providers)}, Enter to keep current): ", end="")
        provider_choice = input().strip()
        
        # Determine selected provider
        if provider_choice:
            try:
                idx = int(provider_choice) - 1
                if 0 <= idx < len(providers):
                    new_provider = providers[idx]
                else:
                    new_provider = self.config.default_provider
            except ValueError:
                new_provider = self.config.default_provider
        else:
            new_provider = self.config.default_provider
        
        # STEP 1b: Check/Get API Key for provider (skip for LOCAL)
        api_key = ""
        if new_provider.upper() != "LOCAL":
            api_key = get_api_key(new_provider)
            
            if not api_key:
                self.console.print()
                self.console.print(f"[bold cyan]üîë API Key Required for {new_provider.upper()}[/]")
                
                if new_provider == "GOOGLE":
                    self.console.print("[dim]Get a key from: https://aistudio.google.com/apikey[/]")
                else:
                    self.console.print("[dim]Get a key from: https://console.groq.com/keys[/]")
                
                self.console.print("API key: ", end="")
                try:
                    import getpass
                    api_key = getpass.getpass(prompt="")
                except Exception:
                    api_key = input()
                
                if not api_key or len(api_key) < 10:
                    self.ui.print_error("Invalid API key. Aborting.")
                    return
                
                save_api_key(new_provider, api_key)
                self.ui.print_system_message("API key saved.", "success")
        
        # STEP 2: Model Selection
        if new_provider.upper() == "LOCAL":
            available_models = ollama_models
            display_names = ollama_models
        else:
            available_models = AVAILABLE_MODELS.get(new_provider, [])
            display_names = available_models
        
        self.console.print()
        self.console.print("[bold cyan]‚îÅ‚îÅ‚îÅ SELECT MODEL ‚îÅ‚îÅ‚îÅ[/]")
        for i, m in enumerate(display_names, 1):
            # Check if this is the current model (handle language suffix)
            full_model = available_models[i-1]
            is_current = self.config.default_model == full_model or self.config.default_model.startswith(m.replace('.gguf', ''))
            indicator = "‚Üí" if is_current else " "
            self.console.print(f"  {indicator} [{i}] {m}")
        
        self.console.print(f"\nChoice (1-{len(available_models)}, default 1): ", end="")
        model_choice = input().strip()
        
        try:
            idx = int(model_choice) - 1
            if 0 <= idx < len(available_models):
                selected_model = available_models[idx]
            else:
                selected_model = available_models[0]
        except ValueError:
            selected_model = available_models[0]
        
        final_model_name = selected_model
        
        # New: Gemma Language Selection Sub-menu (REMOVED)
        # if final_model_name == "gemma-3-27b":
        #    ... (Logic removed as per request)

        
        # STEP 4: Create/Switch Provider if needed
        provider_changed = new_provider.upper() != self.config.default_provider.upper()
        
        if provider_changed:
            try:
                new_provider_instance = self._create_provider(new_provider, api_key, final_model_name)
                
                # Validate new provider (skip for LOCAL - no API key needed)
                if new_provider.upper() != "LOCAL":
                    with self.console.status("[bold purple]Validating API key..."):
                        if not await new_provider_instance.validate_api_key():
                            self.ui.print_error(
                                "Invalid API key.",
                                suggestion="Check your API key and try again."
                            )
                            return
                else:
                    # For LOCAL, just try to load the model
                    self.console.print("[dim]Loading local model...[/]")
                
                # Switch to new provider
                self.provider = new_provider_instance
                self.config.default_provider = new_provider
                
                # Reset provider's internal chat state but keep our context
                if hasattr(self.provider, 'reset_chat'):
                    self.provider.reset_chat()
                    
            except Exception as e:
                self.ui.print_error(f"Failed to switch provider: {e}")
                return
        else:
            # Same provider, just update model
            if self.provider:
                self.provider.set_model(final_model_name)
        
        # STEP 5: Save and confirm
        self.config.default_model = final_model_name
        save_config(self.config)
        
        # Show success message
        context_msg = ""
        if provider_changed and self.context:
            context_msg = f"\nConversation context preserved ({len(self.context)} messages)."
        
        self.console.print()
        self.ui.print_system_message(
            f"Provider: {new_provider.upper()}\n"
            f"Model: {final_model_name}"
            f"{context_msg}",
            style="success"
        )
        
        # Update header
        self.ui.print_header(
            model=final_model_name,
            provider=new_provider
        )

    
    async def _handle_memory_command(self, args: List[str]):
        """Handle /memory command."""
        if not args:
            args = ["list"]
        
        action = args[0]
        
        if action == "list":
            memories = self.memory.list_all(limit=20)
            self.ui.print_memories(memories)
            
        elif action == "search" and len(args) > 1:
            query = " ".join(args[1:])
            results = self.memory.search(query)
            self.ui.print_memories(results)
            
        elif action == "delete" and len(args) > 1:
            try:
                memory_id = int(args[1])
                if self.memory.delete(memory_id):
                    self.ui.print_system_message(
                        f"Memory #{memory_id} deleted.",
                        style="success"
                    )
                else:
                    self.ui.print_error(f"Memory #{memory_id} not found.")
            except ValueError:
                self.ui.print_error("Invalid memory ID.")
                
        elif action == "clear":
            count = self.memory.clear_all()
            self.ui.print_system_message(
                f"Deleted {count} memories.",
                style="warning"
            )
        else:
            self.ui.print_panel(
                "Memory commands:\n\n"
                "  /memory list          - List memories\n"
                "  /memory search <term> - Search memories\n"
                "  /memory delete <id>   - Delete memory\n"
                "  /memory clear         - Delete all",
                title="üß† Memory Management"
            )
    
    def _show_stats(self):
        """Show detailed statistics."""
        session_stats = {}
        if self.provider:
            usage = self.provider.get_session_usage()
            session_stats = {
                "tokens_input": usage.tokens_input,
                "tokens_output": usage.tokens_output,
                "tokens_total": usage.tokens_total,
                "requests_count": usage.requests_count,
            }
        
        db_stats = self.db.get_usage_stats(
            provider=self.config.default_provider
        ) if self.db else {}
        
        self.ui.print_stats(
            session_stats=session_stats,
            db_stats=db_stats,
            provider=self.config.default_provider,
            model=self.config.default_model
        )
    


    async def _handle_kleos_mode(self, original_prompt: str):
        """Handle the multi-stage Kleos mode logic."""
        if not self.provider:
            self.ui.print_error(
                "No AI model selected.",
                suggestion="Use /model to select a provider and model to start chatting."
            )
            return

        from .config import KLEOS_ANALYST_PROMPT, KLEOS_THINKER_PROMPT, UI_MESSAGES
        
        # Language management
        def detect_lang(text: str) -> str:
            lang_keywords = {
                'it': {
                    'il', 'lo', 'la', 'gli', 'le', 'di', 'da', 'in', 'con', 'su', 'per', 'tra', 'fra', 'che', 'non', 'sono', 
                    '√®', 'sono', 'ho', 'ha', 'abbiamo', 'hanno', 'come', 'perch√©', 'quando', 'chi', 'quale', 'questo', 'quello',
                    'filtro', 'olio', 'macchina', 'casa', 'lavoro', 'fare', 'dire', 'potere', 'volere', 'un', 'una', 'uno'
                },
                'es': {
                    'el', 'la', 'los', 'las', 'de', 'en', 'con', 'por', 'para', 'que', 'no', 'son', 
                    'es', 'tengo', 'tiene', 'tenemos', 'tienen', 'como', 'porque', 'cuando', 'quien', 'cual', 'este', 'ese',
                    'hacer', 'decir', 'poder', 'querer', 'un', 'una', 'uno'
                },
                'fr': {
                    'le', 'la', 'les', 'de', 'en', 'avec', 'par', 'pour', 'est', 'que', 'ne', 'sont',
                    'ai', 'as', 'a', 'avons', 'avez', 'ont', 'comment', 'pourquoi', 'quand', 'qui', 'quel', 'ce', 'cette',
                    'faire', 'dire', 'pouvoir', 'vouloir', 'un', 'une'
                },
                'de': {
                    'der', 'die', 'das', 'den', 'dem', 'des', 'ein', 'eine', 'und', 'ist', 'nicht',
                    'habe', 'hat', 'haben', 'wie', 'warum', 'wann', 'wer', 'welcher', 'dieser', 'jener',
                    'machen', 'sagen', 'k√∂nnen', 'wollen'
                },
            }
            # Look for words length >= 2
            words = set(re.findall(r'\b\w{2,}\b', text.lower()))
            scores = {l: len(words.intersection(kws)) for l, kws in lang_keywords.items()}
            
            # Find the best language, but stick to English if no strong signal
            best_lang = max(scores, key=scores.get)
            if scores[best_lang] > 0:
                return best_lang
            return 'en'
            
        lang = detect_lang(original_prompt)
        locale = UI_MESSAGES.get(lang, UI_MESSAGES["en"])
        
        # 1. Activation UI
        timestamp = datetime.now().strftime("%H:%M")
        
        # Clear raw input
        try:
            sys.stdout.write("\033[F\033[K")
            sys.stdout.flush()
        except:
            pass
            
        self.ui.print_kleos_user_message(original_prompt, self.config.user_name, timestamp)
        
        # 2. Analyst Phase - Initial Analysis (Streaming)
        # 2. Analyst Phase - Initial Analysis (Streaming)
        analyst_prompt = KLEOS_ANALYST_PROMPT.replace("[INSERISCI QUI IL PROMPT ORIGINALE O LA DESCRIZIONE DEL TASK]", original_prompt)
        
        cancel_event = asyncio.Event()
        ai_timestamp = datetime.now().strftime("%H:%M")
        
        lang_names = {
            'it': 'Italian',
            'en': 'English',
            'es': 'Spanish',
            'fr': 'French',
            'de': 'German'
        }
        target_lang_name = lang_names.get(lang, 'English')
        
        # Use English for system prompts that control fixed AI logic behavior
        try:
            stream = self.provider.stream_message(
                message=analyst_prompt,
                system_prompt=UI_MESSAGES["en"].get("prompt_analyst_system") + f" Respond ONLY in {target_lang_name}.",
            )
            
            analyst_full_output, _ = await self.ui.stream_ai_message(
                stream=stream,
                model="Analyst",
                timestamp=ai_timestamp,
                cancel_event=cancel_event,
                style="kleos",
                language=lang
            )
        except Exception as e:
            self.ui.print_error(UI_MESSAGES["en"].get("kleos_error_analyst").format(e=e))
            return

        # 3. Step B: User Answers
        self.console.print(f"  [bold {self.ui.colors['kleos']}]{UI_MESSAGES['en'].get('kleos_intro')}[/]")
        user_answer = input("  > ").strip()
        user_details = [user_answer] if user_answer else []
        
        # 4. Generate & Refine Master Prompt Loop
        current_context = f"User details: {chr(10).join(user_details)}" if user_details else ""
        final_prompt = None
        
        while True:
            refinement_input = (
                f"Original prompt: '{original_prompt}'\n"
                f"{current_context}\n\n"
                f"Based on the details, generate the optimized MASTER PROMPT in {target_lang_name}. Output ONLY the prompt content."
            )
            
            try:
                stream = self.provider.stream_message(
                    message=refinement_input,
                    system_prompt=UI_MESSAGES["en"].get("prompt_master_system") + f" Respond ONLY in {target_lang_name}.",
                )
                
                final_prompt, _ = await self.ui.stream_ai_message(
                    stream=stream,
                    model="Master Prompt",
                    timestamp=datetime.now().strftime("%H:%M"),
                    cancel_event=cancel_event,
                    style="kleos",
                    language=lang
                )
            except Exception as e:
                self.ui.print_error(UI_MESSAGES["en"].get("kleos_error_master").format(e=e))
                return

            self.console.print(f"  [bold {self.ui.colors['kleos']}]{UI_MESSAGES['en'].get('kleos_confirm')}[/]", end="")
            choice = input().strip().lower()
            
            if choice in ['y', 'yes', '']:
                break
            else:
                self.console.print(f"  [bold {self.ui.colors['info']}]{UI_MESSAGES['en'].get('kleos_modify')}[/]", end="")
                feedback = input().strip()
                if not feedback:
                    self.ui.print_system_message(UI_MESSAGES["en"].get("kleos_cancelled"), "info")
                    return
                current_context += f"\nUser feedback for modification: {feedback}"

        # 5. Thinker Phase (Deep Reasoning)
        
        # Get relevant memories for the final task
        memories = self.memory.get_relevant_memories(final_prompt)
        memories_context = self.memory.format_memories_for_context(memories)
        
        # Send to AI with Thinker system prompt (Streaming)
        ai_timestamp = datetime.now().strftime("%H:%M")
        
        try:
            stream = self.provider.stream_message(
                message=final_prompt,
                context=[], # Clean context for the Master Prompt to avoid refusals
                system_prompt=KLEOS_THINKER_PROMPT,
                memories=memories_context if memories_context else None,
            )
            
            full_content, self.last_ttft = await self.ui.stream_ai_message(
                stream=stream,
                model="", 
                timestamp=ai_timestamp,
                cancel_event=cancel_event,
                thinking_only=True,
                style="ai",
                language=lang
            )
        except Exception as e:
            self.ui.print_error(locale.get("kleos_error_thinker").format(e=e))
            return

        # 5. Save context
        if full_content:
            self.context.append(Message(role="user", content=original_prompt))
            self.context.append(Message(role="assistant", content=full_content))
            
            if self.config.auto_save_conversations:
                self.db.add_conversation(
                    provider=self.config.default_provider,
                    model=self.config.default_model,
                    user_message=f"[KLEOS] {original_prompt}",
                    ai_response=full_content,
                    tokens_used=0,
                )

    async def _send_to_ai(self, message: str):
        """Send message to AI provider."""
        if not self.provider:
            self.ui.print_error(
                "No AI model selected.",
                suggestion="Use /model to select a provider and model to start chatting."
            )
            return

        # Show user message
        timestamp = datetime.now().strftime("%H:%M")
        
        # CLEAR RAW INPUT TRICK: Move cursor up 1 line and clear it
        # This removes the raw text the user just typed, leaving only the rendered panel below
        try:
            sys.stdout.write("\033[F\033[K")
            sys.stdout.flush()
        except:
            pass
            
        self.ui.print_user_message(message, self.config.user_name, timestamp)
        
        # Get relevant memories
        memories = self.memory.get_relevant_memories(message)
        memories_context = self.memory.format_memories_for_context(memories)
        
        # Get system prompt
        # Language is now centrally managed in config.language
        prompt_lang = self.config.language
            
        system_prompt = get_system_prompt(
            language=prompt_lang, 
            user_name=self.config.user_name,
            provider=self.config.default_provider
        )
        
        # New response logic with streaming and cancellation support
        cancel_event = asyncio.Event()
        full_content = ""
        was_cancelled = False
        
        try:
            # First, start the stream (do not await, it returns an async generator)
            stream = self.provider.stream_message(
                message=message,
                context=self.context,
                system_prompt=system_prompt,
                memories=memories_context if memories_context else None,
            )
            
            # Display response with typewriter effect
            # Wrap in a task so we can cancel it
            ai_timestamp = datetime.now().strftime("%H:%M")
            
            # Create a task for the streaming
            async def _stream_with_cancel():
                return await self.ui.stream_ai_message(
                    stream=stream,
                    model=self.config.default_model,
                    timestamp=ai_timestamp,
                    cancel_event=cancel_event
                )
            
            stream_task = asyncio.create_task(_stream_with_cancel())
            
            # Wait for stream with keyboard interrupt handling
            start_time = asyncio.get_event_loop().time()
            try:
                full_content, self.last_ttft = await stream_task
            except asyncio.CancelledError:
                was_cancelled = True
                full_content = ""
            
            end_time = asyncio.get_event_loop().time()
            total_duration = end_time - start_time
                
        except KeyboardInterrupt:
            # User pressed Ctrl+C - signal cancellation
            cancel_event.set()
            was_cancelled = True
            self.console.print()  # New line after ^C
            
        except Exception as e:
            self.ui.print_error(
                str(e),
                suggestion="Check connection and try again."
            )
            return
        
        # Only update context and save if we got content
        if full_content:
            # Print stats
            tokens_in = 0
            tokens_out = 0
            if self.provider:
                # Estimate if provider doesn't support exact count yet
                tokens_out = len(full_content.split()) * 1.3 # Rough estimate
                tokens_in = len(message.split()) * 1.3
            
            if self.config.show_stats:
                self.ui.print_response_stats(
                    ttft=getattr(self, 'last_ttft', 0.0),
                    tokens_in=int(tokens_in),
                    tokens_out=int(tokens_out),
                    total_time=total_duration
                )

            # Update context
            self.context.append(Message(role="user", content=message))
            self.context.append(Message(role="assistant", content=full_content))
            
            # Trim context if too long
            max_context = self.config.max_context_messages * 2
            if len(self.context) > max_context:
                self.context = self.context[-max_context:]
            
            # Save conversation
            if self.config.auto_save_conversations:
                self.db.add_conversation(
                    provider=self.config.default_provider,
                    model=self.config.default_model,
                    user_message=message,
                    ai_response=full_content,
                    tokens_used=0,
                )
        
        # Usage update hidden by user request (use /stats to see)


# =============================================================================
# Entry Point
# =============================================================================

async def async_main():
    """Main entry point."""
    app = MarkApp()
    
    # Initialize
    if not await app.initialize():
        print("Initialization failed. Exiting.")
        sys.exit(1)
    
    # Run main loop
    await app.run()


def main():
    """Synchronous wrapper for core script execution."""
    try:
        asyncio.run(async_main())
    except KeyboardInterrupt:
        print("\nGoodbye!")
        sys.exit(0)


if __name__ == "__main__":
    main()
